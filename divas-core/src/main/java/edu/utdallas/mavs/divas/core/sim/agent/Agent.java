package edu.utdallas.mavs.divas.core.sim.agent;

import edu.utdallas.mavs.divas.core.sim.agent.knowledge.internal.Goal;
import edu.utdallas.mavs.divas.core.sim.common.state.AgentState;
import edu.utdallas.mavs.divas.core.sim.common.state.CellState;
import edu.utdallas.mavs.divas.core.sim.common.stimulus.Stimuli;

/**
 * This interface describes the basic behavior of an autonomous agent.
 * <p>
 * An autonomous agent partially perceives its environment with an incomplete and non-deterministic view that is passed onto its sensors. This perception is translated into knowledge. With the acquired knowledge, the agent is able to plan its best
 * course of actions and act on its situated environment, by stimulating it.
 */
public interface Agent
{
    /**
     * Gets the ID of the agent
     * 
     * @return the unique ID of the agent
     */
    public int getId();

    /**
     * Makes the agent execute generating {@link Stimuli} in response to its internal deliberation process
     * 
     * @return the set to stimulus generated by the agent
     */
    public Stimuli execute();

    /**
     * Gives the agent a partial view of its situated environment to perceive.
     * 
     * @param cell the partial state of the environmnent
     */
    public void perceive(CellState cell);

    /**
     * Gets the agent's state
     * 
     * @return the agent's state
     */
    public AgentState getState();

    /**
     * Updates the agent's state
     * 
     * @param agentState the new agent state
     */
    public void setState(AgentState agentState);

    /**
     * Adds a new goal to the agent's goal.
     * 
     * @param newGoal new agent goal
     */
    public void addGoal(Goal newGoal);
}
